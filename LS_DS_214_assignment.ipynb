{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LS_DS_214_assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdixson-ds/DS-Unit-2-Linear-Models/blob/master/LS_DS_214_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFYyy7N5VKVB",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "\n",
        "## Assignment ðŸŒ¯\n",
        "\n",
        "You'll use a [**dataset of 400+ burrito reviews**](https://srcole.github.io/100burritos/). How accurately can you predict whether a burrito is rated 'Great'?\n",
        "\n",
        "> We have developed a 10-dimensional system for rating the burritos in San Diego. ... Generate models for what makes a burrito great and investigate correlations in its dimensions.\n",
        "\n",
        "- [X] Do train/validate/test split. Train on reviews from 2016 & earlier. Validate on 2017. Test on 2018 & later.\n",
        "- [X] Begin with baselines for classification.\n",
        "- [X] Use scikit-learn for logistic regression.\n",
        "- [ ] Get your model's validation accuracy. (Multiple times if you try multiple iterations.)\n",
        "- [ ] Get your model's test accuracy. (One time, at the end.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Make exploratory visualizations.\n",
        "- [ ] Do one-hot encoding.\n",
        "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [ ] Get and plot your coefficients.\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTJOczBvVKVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data downloaded from https://srcole.github.io/100burritos/\n",
        "import pandas as pd\n",
        "df = pd.read_csv(DATA_PATH+'burritos/burritos.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8mr_edpVKVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Derive binary classification target:\n",
        "# We define a 'Great' burrito as having an\n",
        "# overall rating of 4 or higher, on a 5 point scale.\n",
        "# Drop unrated burritos.\n",
        "df = df.dropna(subset=['overall'])\n",
        "df['Great'] = df['overall'] >= 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHkFhlzeVKV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean/combine the Burrito categories\n",
        "df['Burrito'] = df['Burrito'].str.lower()\n",
        "\n",
        "california = df['Burrito'].str.contains('california')\n",
        "asada = df['Burrito'].str.contains('asada')\n",
        "surf = df['Burrito'].str.contains('surf')\n",
        "carnitas = df['Burrito'].str.contains('carnitas')\n",
        "\n",
        "df.loc[california, 'Burrito'] = 'California'\n",
        "df.loc[asada, 'Burrito'] = 'Asada'\n",
        "df.loc[surf, 'Burrito'] = 'Surf & Turf'\n",
        "df.loc[carnitas, 'Burrito'] = 'Carnitas'\n",
        "df.loc[~california & ~asada & ~surf & ~carnitas, 'Burrito'] = 'Other'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhD1kZArVKWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some high cardinality categoricals\n",
        "df = df.drop(columns=['Notes', 'Location', 'Reviewer', 'Address', 'URL', 'Neighborhood'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzkAKu24VKWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some columns to prevent \"leakage\"\n",
        "\n",
        "df = df.drop(columns=['Rec', 'overall'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzhs2WoxVKWh",
        "colab_type": "code",
        "outputId": "bec76a5a-e458-440b-e83d-d22f50fe291e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Burrito</th>\n",
              "      <th>Date</th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Unreliable</th>\n",
              "      <th>NonSD</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Chicken</th>\n",
              "      <th>Shrimp</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Rice</th>\n",
              "      <th>Beans</th>\n",
              "      <th>Lettuce</th>\n",
              "      <th>Tomato</th>\n",
              "      <th>Bell peper</th>\n",
              "      <th>Carrots</th>\n",
              "      <th>Cabbage</th>\n",
              "      <th>Sauce</th>\n",
              "      <th>Salsa.1</th>\n",
              "      <th>Cilantro</th>\n",
              "      <th>Onion</th>\n",
              "      <th>Taquito</th>\n",
              "      <th>Pineapple</th>\n",
              "      <th>Ham</th>\n",
              "      <th>Chile relleno</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>California</td>\n",
              "      <td>1/18/2016</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>California</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carnitas</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Asada</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>California</td>\n",
              "      <td>1/27/2016</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>x</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Burrito       Date  Yelp  Google Chips  ...  Sushi  Avocado  Corn  Zucchini  Great\n",
              "0  California  1/18/2016   3.5     4.2   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "1  California  1/24/2016   3.5     3.3   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "2    Carnitas  1/24/2016   NaN     NaN   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "3       Asada  1/24/2016   NaN     NaN   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "4  California  1/27/2016   4.0     3.8     x  ...    NaN      NaN   NaN       NaN   True\n",
              "\n",
              "[5 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogsz2t2oL4Xx",
        "colab_type": "text"
      },
      "source": [
        "Train/validate/test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ_VWn8NAHuQ",
        "colab_type": "code",
        "outputId": "fa800a3b-3c9a-446f-faf1-46ca7f2f935a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Do train/validate/test split. Train on reviews from 2016 & earlier. Validate on 2017. Test on 2018 & later.\n",
        "\n",
        "from datetime import datetime\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
        "df['Date'].describe\n",
        "df.shape"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(421, 59)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-mBHd1CDa10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = df[df['Date'].dt.year <= 2016]\n",
        "val = df[df['Date'].dt.year == 2017]\n",
        "test = df[df['Date'].dt.year >= 2018]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyXcfFiaL_WJ",
        "colab_type": "text"
      },
      "source": [
        "Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paDTSKlpDuVM",
        "colab_type": "code",
        "outputId": "791de52c-744b-4277-df6d-258b58d68c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#Begin with baselines for classification.\n",
        "#Roughly 40% of burritos are 'great'\n",
        "\n",
        "target = 'Great'\n",
        "y_train = train[target]\n",
        "y_train.value_counts(normalize=True)"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    0.590604\n",
              "True     0.409396\n",
              "Name: Great, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nldHwJJ-Ii4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#What if we guessed the majority class for every prediction?\n",
        "\n",
        "majority_class = y_train.mode()[0]\n",
        "y_pred = [majority_class] * len(y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DWrU8PFJK1y",
        "colab_type": "code",
        "outputId": "95838641-736b-4cba-d2f5-b71a7849c280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Training accuracy of majority class baseline = \n",
        "# frequency of majority class (aka base rate)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5906040268456376"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT3M1El4JaVq",
        "colab_type": "code",
        "outputId": "0813137b-c7a6-4131-f982-60fc1b79d8b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Validation accuracy of majority class baseline=\n",
        "#usually similar to Train accuracy\n",
        "\n",
        "y_val = val[target]\n",
        "y_pred = [majority_class] * len(y_val)\n",
        "accuracy_score(y_val, y_pred)"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5529411764705883"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEmPQRc2L06J",
        "colab_type": "text"
      },
      "source": [
        "Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEk4nxQhLjpn",
        "colab_type": "code",
        "outputId": "a40f99a9-54c6-4608-9b70-3352d0a2aa5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "source": [
        "#Start with linear regression for intuition, and fun\n",
        "\n",
        "train.describe().T"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Yelp</th>\n",
              "      <td>71.0</td>\n",
              "      <td>3.897183</td>\n",
              "      <td>0.478680</td>\n",
              "      <td>2.50</td>\n",
              "      <td>3.5000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Google</th>\n",
              "      <td>71.0</td>\n",
              "      <td>4.142254</td>\n",
              "      <td>0.371738</td>\n",
              "      <td>2.90</td>\n",
              "      <td>4.0000</td>\n",
              "      <td>4.20</td>\n",
              "      <td>4.40</td>\n",
              "      <td>4.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cost</th>\n",
              "      <td>292.0</td>\n",
              "      <td>6.896781</td>\n",
              "      <td>1.211412</td>\n",
              "      <td>2.99</td>\n",
              "      <td>6.2500</td>\n",
              "      <td>6.85</td>\n",
              "      <td>7.50</td>\n",
              "      <td>11.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hunger</th>\n",
              "      <td>297.0</td>\n",
              "      <td>3.445286</td>\n",
              "      <td>0.852150</td>\n",
              "      <td>0.50</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mass (g)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Length</th>\n",
              "      <td>175.0</td>\n",
              "      <td>19.829886</td>\n",
              "      <td>2.081275</td>\n",
              "      <td>15.00</td>\n",
              "      <td>18.5000</td>\n",
              "      <td>19.50</td>\n",
              "      <td>21.00</td>\n",
              "      <td>26.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Circum</th>\n",
              "      <td>174.0</td>\n",
              "      <td>22.042241</td>\n",
              "      <td>1.685043</td>\n",
              "      <td>17.00</td>\n",
              "      <td>21.0000</td>\n",
              "      <td>22.00</td>\n",
              "      <td>23.00</td>\n",
              "      <td>27.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Volume</th>\n",
              "      <td>174.0</td>\n",
              "      <td>0.770920</td>\n",
              "      <td>0.137833</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.6625</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.87</td>\n",
              "      <td>1.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tortilla</th>\n",
              "      <td>298.0</td>\n",
              "      <td>3.472315</td>\n",
              "      <td>0.797606</td>\n",
              "      <td>1.40</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Temp</th>\n",
              "      <td>283.0</td>\n",
              "      <td>3.706360</td>\n",
              "      <td>0.991897</td>\n",
              "      <td>1.00</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.50</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Meat</th>\n",
              "      <td>288.0</td>\n",
              "      <td>3.551215</td>\n",
              "      <td>0.869483</td>\n",
              "      <td>1.00</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fillings</th>\n",
              "      <td>297.0</td>\n",
              "      <td>3.519024</td>\n",
              "      <td>0.850348</td>\n",
              "      <td>1.00</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Meat:filling</th>\n",
              "      <td>292.0</td>\n",
              "      <td>3.528870</td>\n",
              "      <td>1.040457</td>\n",
              "      <td>0.50</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Uniformity</th>\n",
              "      <td>296.0</td>\n",
              "      <td>3.395946</td>\n",
              "      <td>1.089044</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2.5000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Salsa</th>\n",
              "      <td>278.0</td>\n",
              "      <td>3.324640</td>\n",
              "      <td>0.971226</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.5000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Synergy</th>\n",
              "      <td>296.0</td>\n",
              "      <td>3.540203</td>\n",
              "      <td>0.922426</td>\n",
              "      <td>1.00</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wrap</th>\n",
              "      <td>296.0</td>\n",
              "      <td>3.955068</td>\n",
              "      <td>1.167341</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.5000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Queso</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                count       mean       std    min      25%    50%    75%    max\n",
              "Yelp             71.0   3.897183  0.478680   2.50   3.5000   4.00   4.00   4.50\n",
              "Google           71.0   4.142254  0.371738   2.90   4.0000   4.20   4.40   4.90\n",
              "Cost            292.0   6.896781  1.211412   2.99   6.2500   6.85   7.50  11.95\n",
              "Hunger          297.0   3.445286  0.852150   0.50   3.0000   3.50   4.00   5.00\n",
              "Mass (g)          0.0        NaN       NaN    NaN      NaN    NaN    NaN    NaN\n",
              "Density (g/mL)    0.0        NaN       NaN    NaN      NaN    NaN    NaN    NaN\n",
              "Length          175.0  19.829886  2.081275  15.00  18.5000  19.50  21.00  26.00\n",
              "Circum          174.0  22.042241  1.685043  17.00  21.0000  22.00  23.00  27.00\n",
              "Volume          174.0   0.770920  0.137833   0.40   0.6625   0.75   0.87   1.24\n",
              "Tortilla        298.0   3.472315  0.797606   1.40   3.0000   3.50   4.00   5.00\n",
              "Temp            283.0   3.706360  0.991897   1.00   3.0000   4.00   4.50   5.00\n",
              "Meat            288.0   3.551215  0.869483   1.00   3.0000   3.50   4.00   5.00\n",
              "Fillings        297.0   3.519024  0.850348   1.00   3.0000   3.50   4.00   5.00\n",
              "Meat:filling    292.0   3.528870  1.040457   0.50   3.0000   4.00   4.00   5.00\n",
              "Uniformity      296.0   3.395946  1.089044   1.00   2.5000   3.50   4.00   5.00\n",
              "Salsa           278.0   3.324640  0.971226   0.00   2.5000   3.50   4.00   5.00\n",
              "Synergy         296.0   3.540203  0.922426   1.00   3.0000   3.75   4.00   5.00\n",
              "Wrap            296.0   3.955068  1.167341   0.00   3.5000   4.00   5.00   5.00\n",
              "Queso             0.0        NaN       NaN    NaN      NaN    NaN    NaN    NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF87zH3iLyHc",
        "colab_type": "code",
        "outputId": "8d29f669-4af0-4a56-9260-c4acac5c837f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "#1 Import estimator class\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#2 Instantiate this class\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "#3 Arrange X feature matrices(already did y target vectors)\n",
        "features = ['Fillings', 'Tortilla', 'Temp', 'Yelp', 'Google', 'Cost', 'Hunger', 'Length', 'Circum', 'Volume', 'Meat:filling', 'Uniformity', 'Salsa', 'Synergy', 'Wrap']\n",
        "#no more than 3 features?\n",
        "\n",
        "X_train = train[features]\n",
        "X_val = val[features]\n",
        "\n",
        "#4 Impute missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_val_imputed = imputer.transform(X_val)\n",
        "\n",
        "#5 Fit the model\n",
        "linear_reg.fit(X_train_imputed, y_train)\n",
        "\n",
        "linear_reg.predict(X_val_imputed)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.59629459e-01,  5.00336082e-01,  6.22112082e-01,  5.52274611e-01,\n",
              "       -1.51925605e-01,  1.04004826e-01,  8.23107059e-01,  5.08672502e-01,\n",
              "       -1.70409788e-01,  7.86243293e-01,  7.55231376e-01, -1.46691755e-02,\n",
              "        2.23344311e-01,  3.06587291e-01,  1.02409648e+00,  4.35329463e-01,\n",
              "        4.83805105e-01,  6.09326466e-01,  5.89047845e-01,  1.06124307e+00,\n",
              "        6.27601313e-01,  4.58249811e-01,  1.16734850e-01,  5.17722880e-01,\n",
              "        6.88997463e-01,  6.04612099e-01,  6.65960121e-01,  3.60527796e-01,\n",
              "        4.56473830e-01,  5.57149931e-01,  7.80288371e-01,  4.26707045e-01,\n",
              "        2.50395270e-01,  3.30806118e-01, -3.60861966e-02,  9.86974490e-03,\n",
              "        3.74702276e-01,  5.84150632e-01,  4.16617674e-01,  6.28356221e-01,\n",
              "        3.08932411e-01,  4.71890931e-01,  5.11482333e-01,  5.85677855e-01,\n",
              "        5.79503522e-01,  4.36521445e-01,  1.33290759e-01,  3.15396906e-01,\n",
              "        6.31253150e-01, -1.50334222e-01,  1.16174565e-01,  4.65089340e-01,\n",
              "        8.25135451e-01,  7.84046051e-01,  4.50359819e-01,  1.94864783e-01,\n",
              "        2.10974363e-01,  2.61920291e-01,  3.14746179e-01,  3.54055084e-01,\n",
              "       -4.34900975e-01,  3.27635253e-01,  1.14665427e-04,  4.75772948e-01,\n",
              "        5.64706151e-01,  8.82016979e-01,  5.72404288e-01,  9.41864665e-01,\n",
              "        5.53309768e-01,  4.70245988e-01,  1.42263676e+00,  8.49752070e-01,\n",
              "        5.99675194e-01,  7.51429527e-01, -5.24204360e-02,  4.23335029e-01,\n",
              "        7.74393853e-02,  7.21610250e-01,  7.12124470e-01,  9.07369336e-01,\n",
              "        5.61442952e-01,  6.61437402e-01,  5.28068197e-01,  6.17210228e-01,\n",
              "        1.15654928e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEKEoEEmQrq8",
        "colab_type": "code",
        "outputId": "ff65b190-45ce-4f07-d663-708bb0341023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "#Get coefficients\n",
        "pd.Series(linear_reg.coef_, features)"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Fillings        0.122041\n",
              "Tortilla        0.060644\n",
              "Temp            0.060389\n",
              "Yelp            0.111010\n",
              "Google         -0.163567\n",
              "Cost            0.045113\n",
              "Hunger          0.006209\n",
              "Length          0.101441\n",
              "Circum          0.182075\n",
              "Volume         -2.641897\n",
              "Meat:filling    0.076355\n",
              "Uniformity      0.015462\n",
              "Salsa           0.041453\n",
              "Synergy         0.157585\n",
              "Wrap            0.004014\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a3wXdwMSa70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test_case = [[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]] #hot burrito?\n",
        "#linear_reg.predict(test_case)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7iQoW33kCt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "#y_pred_train = model.predict(X_train_imputed)\n",
        "#mae = mean_absolute_error(y_train, y_pred_train)\n",
        "#print(f'Train Error: {mae:.2f} ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVV5tbXrW3Yv",
        "colab_type": "text"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY19r9QzJ2o6",
        "colab_type": "code",
        "outputId": "03a01dbe-5f0a-490d-9687-d87ea4e776d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Use scikit-learn for logistic regression\n",
        "#Is the validation better than the baseline? yes\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression(solver='lbfgs', max_iter=300)\n",
        "log_reg.fit(X_train_imputed, y_train)\n",
        "print('Validation Accuracy', log_reg.score(X_val_imputed, y_val))"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8470588235294118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltsVbB4UTT26",
        "colab_type": "code",
        "outputId": "e66624ba-f2fa-4e27-9c4a-4d0e5cad9061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "#This is what predictions look like\n",
        "\n",
        "log_reg.predict(X_val_imputed)"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False,  True,  True, False, False,  True,  True, False,\n",
              "        True,  True, False, False, False,  True, False, False,  True,\n",
              "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
              "       False,  True,  True,  True, False, False, False, False, False,\n",
              "       False,  True, False,  True, False,  True,  True,  True,  True,\n",
              "       False, False, False,  True, False, False, False,  True,  True,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True, False, False, False,  True,  True,  True,  True,\n",
              "        True, False,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptu2UmUbTkbN",
        "colab_type": "code",
        "outputId": "922a5a64-c618-449c-e046-bcb880ac7728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "log_reg.predict(test_case)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju4yf61ITxTa",
        "colab_type": "code",
        "outputId": "8d130041-7450-44ee-b864-4aad63546687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "log_reg.predict_proba(test_case)"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.70511218, 0.29488782]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH9K5ADQV-Cv",
        "colab_type": "code",
        "outputId": "fb80b565-eca0-47b8-9fec-8ae5320f4553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "log_reg.coef_"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.50521817,  0.6697534 ,  0.6015295 ,  0.27129933, -0.18532562,\n",
              "         0.39927913,  0.16003182,  0.05325453,  0.03789849, -0.04400453,\n",
              "         1.14763786,  0.12967097,  0.38111832,  1.84557395,  0.1412405 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB5POJNnWCFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The logistic sigmoid 'squishing' function, implemented to accept numpy arrays\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/ (1 + np.e**(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZl7W6q2WWAY",
        "colab_type": "code",
        "outputId": "ad0a03e0-47e1-44d3-d977-56d13409c0da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sigmoid(log_reg.intercept_ + np.dot(log_reg.coef_, np.transpose(test_case)))"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.29488782]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCOq2y2qW-sD",
        "colab_type": "text"
      },
      "source": [
        "Get validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0G211e-XECv",
        "colab_type": "code",
        "outputId": "e74b950d-053f-41a9-b0c9-c40562d378b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "features = ['Fillings', 'Tortilla', 'Temp', 'Yelp', 'Google', 'Cost', 'Hunger', 'Length', 'Circum', 'Volume', 'Meat:filling', 'Uniformity', 'Salsa', 'Synergy', 'Wrap']\n",
        "target = 'Great'\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "\n",
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((298, 15), (298,), (85, 15), (85,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpKtsu_vZNNr",
        "colab_type": "text"
      },
      "source": [
        "Plot coefficients:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsmDJ52GZTUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWFbr91uZw4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhvFbCkQamHa",
        "colab_type": "code",
        "outputId": "f9943ad6-d1fe-4404-f1a6-2a28fc093151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "X_train_encoded.head()"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Fillings  Tortilla  Temp  Yelp  ...  Uniformity  Salsa  Synergy  Wrap\n",
              "0       3.5       3.0   5.0   3.5  ...         4.0    4.0      4.0   4.0\n",
              "1       2.5       2.0   3.5   3.5  ...         4.0    3.5      2.5   5.0\n",
              "2       3.0       3.0   2.0   NaN  ...         4.0    3.0      3.0   5.0\n",
              "3       3.0       3.0   2.0   NaN  ...         5.0    4.0      4.0   5.0\n",
              "4       3.5       4.0   5.0   4.0  ...         5.0    2.5      4.5   4.0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKPmnywKcg9D",
        "colab_type": "code",
        "outputId": "2d033fb2-5885-49bc-8156-8326b50ba71d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "X_val_encoded.head()"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.60</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.0</td>\n",
              "      <td>20.5</td>\n",
              "      <td>0.77</td>\n",
              "      <td>3.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.60</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.5</td>\n",
              "      <td>21.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.2</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.50</td>\n",
              "      <td>3.9</td>\n",
              "      <td>21.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.74</td>\n",
              "      <td>3.7</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>4.20</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.90</td>\n",
              "      <td>4.0</td>\n",
              "      <td>20.5</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.72</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.80</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.99</td>\n",
              "      <td>3.5</td>\n",
              "      <td>18.5</td>\n",
              "      <td>22.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Fillings  Tortilla  Temp  Yelp  ...  Uniformity  Salsa  Synergy  Wrap\n",
              "301       3.5       4.0   4.5   NaN  ...         5.0    1.5     3.50   4.5\n",
              "302       4.0       4.0   2.0   NaN  ...         4.6    4.2     3.75   5.0\n",
              "303       3.0       3.0   4.5   NaN  ...         4.0    4.3     4.20   5.0\n",
              "304       3.0       3.5   4.0   NaN  ...         4.5    4.0     3.80   4.8\n",
              "305       2.5       2.5   4.5   NaN  ...         3.0    2.0     2.00   4.0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_pdtOUhcmSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train_encoded)\n",
        "X_val_imputed = imputer.transform(X_val_encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8YqKrLwc6rv",
        "colab_type": "code",
        "outputId": "548d448d-7c98-4cc0-d146-5392b43659a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "X_train_imputed[:5]"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.5       ,  3.        ,  5.        ,  3.5       ,  4.2       ,\n",
              "         6.49      ,  3.        , 19.82988571, 22.04224138,  0.77091954,\n",
              "         4.        ,  4.        ,  4.        ,  4.        ,  4.        ],\n",
              "       [ 2.5       ,  2.        ,  3.5       ,  3.5       ,  3.3       ,\n",
              "         5.45      ,  3.5       , 19.82988571, 22.04224138,  0.77091954,\n",
              "         2.        ,  4.        ,  3.5       ,  2.5       ,  5.        ],\n",
              "       [ 3.        ,  3.        ,  2.        ,  3.8971831 ,  4.14225352,\n",
              "         4.85      ,  1.5       , 19.82988571, 22.04224138,  0.77091954,\n",
              "         4.5       ,  4.        ,  3.        ,  3.        ,  5.        ],\n",
              "       [ 3.        ,  3.        ,  2.        ,  3.8971831 ,  4.14225352,\n",
              "         5.25      ,  2.        , 19.82988571, 22.04224138,  0.77091954,\n",
              "         4.        ,  5.        ,  4.        ,  4.        ,  5.        ],\n",
              "       [ 3.5       ,  4.        ,  5.        ,  4.        ,  3.8       ,\n",
              "         6.59      ,  4.        , 19.82988571, 22.04224138,  0.77091954,\n",
              "         4.5       ,  5.        ,  2.5       ,  4.5       ,  4.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY1pdTsPc_1W",
        "colab_type": "code",
        "outputId": "e3695200-48d8-4062-a79d-53fe074a7cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "#this line of code turns it back into a pandas dataframe\n",
        "\n",
        "pd.DataFrame(X_train_imputed, columns=X_train_encoded.columns)"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19.829886</td>\n",
              "      <td>22.042241</td>\n",
              "      <td>0.77092</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>19.829886</td>\n",
              "      <td>22.042241</td>\n",
              "      <td>0.77092</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.50000</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.897183</td>\n",
              "      <td>4.142254</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>19.829886</td>\n",
              "      <td>22.042241</td>\n",
              "      <td>0.77092</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.897183</td>\n",
              "      <td>4.142254</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.829886</td>\n",
              "      <td>22.042241</td>\n",
              "      <td>0.77092</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.829886</td>\n",
              "      <td>22.042241</td>\n",
              "      <td>0.77092</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.50000</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.300000</td>\n",
              "      <td>5.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.75000</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>2.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.897183</td>\n",
              "      <td>4.142254</td>\n",
              "      <td>5.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>20.500000</td>\n",
              "      <td>0.64000</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>3.3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.700000</td>\n",
              "      <td>7.75</td>\n",
              "      <td>4.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.70000</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2.20000</td>\n",
              "      <td>3.3</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.897183</td>\n",
              "      <td>4.142254</td>\n",
              "      <td>7.75</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.68000</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.00000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>4.600000</td>\n",
              "      <td>6.99</td>\n",
              "      <td>3.7</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>0.65000</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.3</td>\n",
              "      <td>3.32464</td>\n",
              "      <td>3.8</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>298 rows Ã— 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Fillings  Tortilla  Temp      Yelp  ...  Uniformity    Salsa  Synergy  Wrap\n",
              "0         3.5       3.0   5.0  3.500000  ...         4.0  4.00000      4.0   4.0\n",
              "1         2.5       2.0   3.5  3.500000  ...         4.0  3.50000      2.5   5.0\n",
              "2         3.0       3.0   2.0  3.897183  ...         4.0  3.00000      3.0   5.0\n",
              "3         3.0       3.0   2.0  3.897183  ...         5.0  4.00000      4.0   5.0\n",
              "4         3.5       4.0   5.0  4.000000  ...         5.0  2.50000      4.5   4.0\n",
              "..        ...       ...   ...       ...  ...         ...      ...      ...   ...\n",
              "293       3.0       4.0   1.5  4.000000  ...         4.0  3.00000      2.0   4.5\n",
              "294       2.0       4.5   5.0  3.897183  ...         3.5  3.00000      2.5   3.0\n",
              "295       3.3       3.5   2.5  3.500000  ...         2.3  2.20000      3.3   4.5\n",
              "296       2.0       4.0   4.5  3.897183  ...         3.5  2.00000      2.0   4.0\n",
              "297       3.0       3.6   4.0  4.500000  ...         4.3  3.32464      3.8   2.0\n",
              "\n",
              "[298 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYiXXScsdWXn",
        "colab_type": "code",
        "outputId": "8cd6af19-abb8-4811-8dc8-c6338057cb39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "X_val_imputed[:5]"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.5       ,  4.        ,  4.5       ,  3.8971831 ,  4.14225352,\n",
              "         6.6       ,  3.4452862 , 23.        , 20.5       ,  0.77      ,\n",
              "         3.5       ,  5.        ,  1.5       ,  3.5       ,  4.5       ],\n",
              "       [ 4.        ,  4.        ,  2.        ,  3.8971831 ,  4.14225352,\n",
              "         6.6       ,  3.4452862 , 20.5       , 21.5       ,  0.75      ,\n",
              "         3.52886986,  4.6       ,  4.2       ,  3.75      ,  5.        ],\n",
              "       [ 3.        ,  3.        ,  4.5       ,  3.8971831 ,  4.14225352,\n",
              "         8.5       ,  3.9       , 21.        , 21.        ,  0.74      ,\n",
              "         3.7       ,  4.        ,  4.3       ,  4.2       ,  5.        ],\n",
              "       [ 3.        ,  3.5       ,  4.        ,  3.8971831 ,  4.14225352,\n",
              "         7.9       ,  4.        , 20.5       , 21.        ,  0.72      ,\n",
              "         4.        ,  4.5       ,  4.        ,  3.8       ,  4.8       ],\n",
              "       [ 2.5       ,  2.5       ,  4.5       ,  3.8971831 ,  4.14225352,\n",
              "         4.99      ,  3.5       , 18.5       , 22.5       ,  0.75      ,\n",
              "         3.        ,  3.        ,  2.        ,  2.        ,  4.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyvYSHLEd0q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_val_scaled = scaler.transform(X_val_imputed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P0xFXV_eC_I",
        "colab_type": "code",
        "outputId": "e2026ba5-9fee-4597-d6c8-ba57cc3c777f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "X_train_scaled"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.02244697, -0.59316238,  1.34069563, ...,  0.72124523,\n",
              "         0.50099338,  0.03868647],\n",
              "       [-1.20240271, -1.84902306, -0.21386677, ...,  0.18727406,\n",
              "        -1.13340089,  0.89967866],\n",
              "       [-0.61242484, -0.59316238, -1.76842918, ..., -0.34669711,\n",
              "        -0.5886028 ,  0.89967866],\n",
              "       ...,\n",
              "       [-0.25843812,  0.03476795, -1.25024171, ..., -1.20105098,\n",
              "        -0.26172395,  0.46918257],\n",
              "       [-1.79238058,  0.66269829,  0.82250816, ..., -1.41463945,\n",
              "        -1.67819898,  0.03868647],\n",
              "       [-0.61242484,  0.16035402,  0.3043207 , ...,  0.        ,\n",
              "         0.28307414, -1.6832979 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6ble6OIeHbX",
        "colab_type": "code",
        "outputId": "bc36f5ad-1e55-4c7e-a315-541d33f4121c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model = LogisticRegressionCV()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print('Validation Accuracy', model.score(X_val_scaled, y_val))"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8352941176470589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN4JpgQMeffo",
        "colab_type": "code",
        "outputId": "ba196f07-c6f5-4761-c299-c24e00751a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "coefficients = pd.Series(model.coef_[0], X_train_encoded.columns)\n",
        "coefficients.sort_values().plot.barh();"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAD4CAYAAADYU1DBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4RKhjClcFmr",
        "colab_type": "code",
        "outputId": "b28248c6-7e63-4699-a685-ac4f49cc0d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "X_train_encoded.columns"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Fillings', 'Tortilla', 'Temp', 'Yelp', 'Google', 'Cost', 'Hunger',\n",
              "       'Length', 'Circum', 'Volume', 'Meat:filling', 'Uniformity', 'Salsa',\n",
              "       'Synergy', 'Wrap'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF6UfLWkXQo5",
        "colab_type": "text"
      },
      "source": [
        "Try with feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fOI-qyIWhLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.feature_selection import f_regression, SelectKBest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx8Ztin5XQF1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "30d35552-c52e-4aa3-97d8-4ad2c82d2d0d"
      },
      "source": [
        "model = LogisticRegressionCV()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print('Validation Accuracy', model.score(X_val_scaled, y_val))"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8352941176470589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfhjfKcpZd-A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "338b1fdb-6d53-4b10-8367-c4eac3fb42b4"
      },
      "source": [
        "    selector = SelectKBest(score_func=f_regression, k=15)\n",
        "    X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
        "    X_test_selected = selector.transform(X_val_scaled)\n",
        "    model = LogisticRegressionCV()\n",
        "    model.fit(X_train_selected, y_train)\n",
        "    y_pred = model.predict(X_test_selected)\n",
        "    print('Validation Accuracy', model.score(X_val_scaled, y_val))\n",
        " "
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8352941176470589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unYF9tbyzZVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #Get your model's test accuracy. (One time, at the end.)\n",
        "\n",
        "X_test = test[features]\n",
        "y_test = test[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLdv7BNBzfiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_encoded = encoder.fit_transform(X_test)\n",
        "X_test_imputed = imputer.fit_transform(X_test_encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmcf-znCzqpB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "313564c1-e573-4c9e-cabc-ece622900876"
      },
      "source": [
        "print('Validation Accuracy', model.score(X_test_imputed, y_test))"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.5789473684210527\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}